{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torch_02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcapMHEYV8DH"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from torch import optim\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkQjycMzWl3l",
        "outputId": "3ffeabf2-bc54-497f-ce84-c901f639f56c"
      },
      "source": [
        "train_dataset = torchvision.datasets.CIFAR100(root='data/',\n",
        "                                             train=True,  \n",
        "                                             transform=transforms.ToTensor(), \n",
        "                                             download=True)\n",
        "\n",
        "\n",
        "image, label = train_dataset[0]\n",
        "print (image.size())\n",
        "print (label)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "torch.Size([3, 32, 32])\n",
            "19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "huyLwTFSW4v5",
        "outputId": "293d3df7-ecfa-4fa2-d216-3ec1723c1464"
      },
      "source": [
        "plt.imshow(image.permute(1, 2, 0).numpy())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8f89d4b090>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjIwEXAxXIEf"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=64, \n",
        "                                           shuffle=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxRRvOpaXQuZ",
        "outputId": "759c87f5-143c-43b9-c8a0-4ff928770602"
      },
      "source": [
        "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                       download=True, transform=transforms.ToTensor())\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4,\n",
        "                                         shuffle=False)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ytgc_FrWLK7K",
        "outputId": "49122319-2842-4ee1-d533-13234c4a6244"
      },
      "source": [
        "for X, y in test_loader:\n",
        "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
        "    print(\"Shape of y: \", y.shape, y.dtype)\n",
        "    break"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]:  torch.Size([4, 3, 32, 32])\n",
            "Shape of y:  torch.Size([4]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTbuoeYXXgLJ"
      },
      "source": [
        "classes = train_loader.dataset.classes"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKNHLdQAXpFg",
        "outputId": "f4c503fc-875d-457c-972b-a0e583fd101d"
      },
      "source": [
        "len(classes)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5KOyoEVNL74",
        "outputId": "08661af6-e670-4a75-9206-7eed4ed33094"
      },
      "source": [
        "x = 1\n",
        "max(0.1*x, 0.5*x)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjeLD59gYRJt",
        "outputId": "67864682-63c0-43ea-8623-ffb07adc637b"
      },
      "source": [
        "32 * 32 * 2 /2 / 2 / 2 / 2"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD0FUuxiX5up",
        "outputId": "bd08e62b-fda5-41b1-9fce-cfd04ec548b0"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "DROPOUT_RATE = 0,5\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_channels, hidden_dim, output_channels):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(input_channels, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.final_linear = nn.Linear(hidden_dim, output_channels)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear_relu_stack(x)\n",
        "        x = self.final_linear(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net(3*32*32, 512, 100).to(device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH662neKPaxE",
        "outputId": "3de5c9e5-73b2-407f-f6fe-68c619ec23f1"
      },
      "source": [
        "\n",
        "print(net)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=3072, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (final_linear): Linear(in_features=512, out_features=100, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "a-6t73-4Yi54",
        "outputId": "698dc23a-03b6-4670-fd4e-77cb70e241a5"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7a499fd04154>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkUWq0nzYneY"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mn9sAl3QX3S"
      },
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # pred = model(X)\n",
        "        # loss = loss_fn(pred, y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzEP5hXQYpQB"
      },
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LWjrp2ErR6i4",
        "outputId": "7ca0fa37-59ac-4f77-d738-dddc6be5b770"
      },
      "source": [
        "epochs = 10000\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_loader, net, loss_fn, optimizer)\n",
        "    test(test_loader, net, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.863658  [    0/50000]\n",
            "loss: 2.997406  [ 6400/50000]\n",
            "loss: 3.540434  [12800/50000]\n",
            "loss: 3.062078  [19200/50000]\n",
            "loss: 3.055332  [25600/50000]\n",
            "loss: 3.095087  [32000/50000]\n",
            "loss: 2.971152  [38400/50000]\n",
            "loss: 3.200524  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 23.2%, Avg loss: 3.256983 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 3.148627  [    0/50000]\n",
            "loss: 2.770233  [ 6400/50000]\n",
            "loss: 2.991114  [12800/50000]\n",
            "loss: 2.942281  [19200/50000]\n",
            "loss: 3.223919  [25600/50000]\n",
            "loss: 3.290008  [32000/50000]\n",
            "loss: 2.757535  [38400/50000]\n",
            "loss: 3.161375  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 23.3%, Avg loss: 3.236166 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.812153  [    0/50000]\n",
            "loss: 2.832550  [ 6400/50000]\n",
            "loss: 2.874180  [12800/50000]\n",
            "loss: 2.764194  [19200/50000]\n",
            "loss: 2.878758  [25600/50000]\n",
            "loss: 3.104183  [32000/50000]\n",
            "loss: 3.370643  [38400/50000]\n",
            "loss: 3.043838  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 23.1%, Avg loss: 3.239381 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 3.044137  [    0/50000]\n",
            "loss: 3.153683  [ 6400/50000]\n",
            "loss: 2.954447  [12800/50000]\n",
            "loss: 3.195974  [19200/50000]\n",
            "loss: 2.824731  [25600/50000]\n",
            "loss: 3.279378  [32000/50000]\n",
            "loss: 3.077510  [38400/50000]\n",
            "loss: 2.788295  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 23.3%, Avg loss: 3.229194 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 2.747830  [    0/50000]\n",
            "loss: 3.203103  [ 6400/50000]\n",
            "loss: 3.068579  [12800/50000]\n",
            "loss: 3.097151  [19200/50000]\n",
            "loss: 3.324483  [25600/50000]\n",
            "loss: 3.159305  [32000/50000]\n",
            "loss: 3.077803  [38400/50000]\n",
            "loss: 3.298254  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 24.2%, Avg loss: 3.201885 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 2.621187  [    0/50000]\n",
            "loss: 2.969084  [ 6400/50000]\n",
            "loss: 3.287438  [12800/50000]\n",
            "loss: 2.883151  [19200/50000]\n",
            "loss: 2.959882  [25600/50000]\n",
            "loss: 2.646846  [32000/50000]\n",
            "loss: 3.138105  [38400/50000]\n",
            "loss: 2.909302  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 24.0%, Avg loss: 3.218297 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 2.902237  [    0/50000]\n",
            "loss: 3.302879  [ 6400/50000]\n",
            "loss: 2.850330  [12800/50000]\n",
            "loss: 3.063037  [19200/50000]\n",
            "loss: 3.029401  [25600/50000]\n",
            "loss: 2.849104  [32000/50000]\n",
            "loss: 2.842299  [38400/50000]\n",
            "loss: 2.939867  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 24.5%, Avg loss: 3.175271 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 2.872606  [    0/50000]\n",
            "loss: 2.932577  [ 6400/50000]\n",
            "loss: 2.846477  [12800/50000]\n",
            "loss: 2.673959  [19200/50000]\n",
            "loss: 2.839155  [25600/50000]\n",
            "loss: 2.735117  [32000/50000]\n",
            "loss: 3.093488  [38400/50000]\n",
            "loss: 2.920126  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 24.4%, Avg loss: 3.180501 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 3.238281  [    0/50000]\n",
            "loss: 2.864257  [ 6400/50000]\n",
            "loss: 2.842519  [12800/50000]\n",
            "loss: 2.889896  [19200/50000]\n",
            "loss: 2.710934  [25600/50000]\n",
            "loss: 2.770318  [32000/50000]\n",
            "loss: 3.117610  [38400/50000]\n",
            "loss: 2.784224  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 24.7%, Avg loss: 3.179792 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 2.779358  [    0/50000]\n",
            "loss: 2.184951  [ 6400/50000]\n",
            "loss: 2.854826  [12800/50000]\n",
            "loss: 3.239832  [19200/50000]\n",
            "loss: 2.616074  [25600/50000]\n",
            "loss: 2.924319  [32000/50000]\n",
            "loss: 3.280780  [38400/50000]\n",
            "loss: 2.968790  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 24.4%, Avg loss: 3.191796 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 2.488831  [    0/50000]\n",
            "loss: 2.752498  [ 6400/50000]\n",
            "loss: 2.770263  [12800/50000]\n",
            "loss: 2.956697  [19200/50000]\n",
            "loss: 2.443682  [25600/50000]\n",
            "loss: 2.877326  [32000/50000]\n",
            "loss: 3.039550  [38400/50000]\n",
            "loss: 2.718954  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 25.0%, Avg loss: 3.164098 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 2.859109  [    0/50000]\n",
            "loss: 3.130955  [ 6400/50000]\n",
            "loss: 3.180636  [12800/50000]\n",
            "loss: 2.865065  [19200/50000]\n",
            "loss: 2.727706  [25600/50000]\n",
            "loss: 2.861341  [32000/50000]\n",
            "loss: 2.638079  [38400/50000]\n",
            "loss: 3.045742  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 24.9%, Avg loss: 3.158575 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 2.753070  [    0/50000]\n",
            "loss: 2.763812  [ 6400/50000]\n",
            "loss: 2.758962  [12800/50000]\n",
            "loss: 3.156951  [19200/50000]\n",
            "loss: 3.131014  [25600/50000]\n",
            "loss: 2.990897  [32000/50000]\n",
            "loss: 2.640584  [38400/50000]\n",
            "loss: 2.876022  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 24.6%, Avg loss: 3.210114 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 3.065941  [    0/50000]\n",
            "loss: 3.073282  [ 6400/50000]\n",
            "loss: 2.903807  [12800/50000]\n",
            "loss: 3.031777  [19200/50000]\n",
            "loss: 3.116551  [25600/50000]\n",
            "loss: 2.596038  [32000/50000]\n",
            "loss: 2.872807  [38400/50000]\n",
            "loss: 2.235247  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 25.5%, Avg loss: 3.158814 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 3.045852  [    0/50000]\n",
            "loss: 2.656750  [ 6400/50000]\n",
            "loss: 2.699923  [12800/50000]\n",
            "loss: 2.756554  [19200/50000]\n",
            "loss: 2.782563  [25600/50000]\n",
            "loss: 2.888957  [32000/50000]\n",
            "loss: 2.677651  [38400/50000]\n",
            "loss: 3.003684  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 25.9%, Avg loss: 3.138870 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 2.635890  [    0/50000]\n",
            "loss: 3.059999  [ 6400/50000]\n",
            "loss: 3.042909  [12800/50000]\n",
            "loss: 2.740037  [19200/50000]\n",
            "loss: 2.683557  [25600/50000]\n",
            "loss: 2.753212  [32000/50000]\n",
            "loss: 2.549920  [38400/50000]\n",
            "loss: 3.053242  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 25.9%, Avg loss: 3.127661 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 2.699066  [    0/50000]\n",
            "loss: 2.619986  [ 6400/50000]\n",
            "loss: 2.771532  [12800/50000]\n",
            "loss: 2.929100  [19200/50000]\n",
            "loss: 2.519074  [25600/50000]\n",
            "loss: 3.033724  [32000/50000]\n",
            "loss: 3.047574  [38400/50000]\n",
            "loss: 2.928580  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 26.2%, Avg loss: 3.109971 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 2.777651  [    0/50000]\n",
            "loss: 2.809798  [ 6400/50000]\n",
            "loss: 2.986572  [12800/50000]\n",
            "loss: 2.400792  [19200/50000]\n",
            "loss: 2.602745  [25600/50000]\n",
            "loss: 2.595071  [32000/50000]\n",
            "loss: 2.361182  [38400/50000]\n",
            "loss: 2.923226  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 25.7%, Avg loss: 3.129944 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 2.747509  [    0/50000]\n",
            "loss: 2.845506  [ 6400/50000]\n",
            "loss: 2.615408  [12800/50000]\n",
            "loss: 2.677712  [19200/50000]\n",
            "loss: 2.736753  [25600/50000]\n",
            "loss: 2.902289  [32000/50000]\n",
            "loss: 2.605976  [38400/50000]\n",
            "loss: 3.145051  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 25.4%, Avg loss: 3.119226 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 2.646797  [    0/50000]\n",
            "loss: 2.608772  [ 6400/50000]\n",
            "loss: 2.565200  [12800/50000]\n",
            "loss: 2.839866  [19200/50000]\n",
            "loss: 2.806471  [25600/50000]\n",
            "loss: 2.943772  [32000/50000]\n",
            "loss: 2.928499  [38400/50000]\n",
            "loss: 2.751396  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 25.8%, Avg loss: 3.127313 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 2.555772  [    0/50000]\n",
            "loss: 2.823091  [ 6400/50000]\n",
            "loss: 2.531862  [12800/50000]\n",
            "loss: 2.890976  [19200/50000]\n",
            "loss: 2.475509  [25600/50000]\n",
            "loss: 2.934807  [32000/50000]\n",
            "loss: 2.692794  [38400/50000]\n",
            "loss: 2.991551  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 26.2%, Avg loss: 3.113913 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 2.759022  [    0/50000]\n",
            "loss: 2.803892  [ 6400/50000]\n",
            "loss: 2.819999  [12800/50000]\n",
            "loss: 2.799773  [19200/50000]\n",
            "loss: 3.243151  [25600/50000]\n",
            "loss: 2.717215  [32000/50000]\n",
            "loss: 2.928198  [38400/50000]\n",
            "loss: 2.598853  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 26.1%, Avg loss: 3.118001 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 2.244271  [    0/50000]\n",
            "loss: 2.746585  [ 6400/50000]\n",
            "loss: 2.709328  [12800/50000]\n",
            "loss: 3.035785  [19200/50000]\n",
            "loss: 2.856437  [25600/50000]\n",
            "loss: 3.087505  [32000/50000]\n",
            "loss: 2.610446  [38400/50000]\n",
            "loss: 2.888358  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 26.6%, Avg loss: 3.092361 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 2.897819  [    0/50000]\n",
            "loss: 2.516015  [ 6400/50000]\n",
            "loss: 2.794385  [12800/50000]\n",
            "loss: 2.629464  [19200/50000]\n",
            "loss: 2.937840  [25600/50000]\n",
            "loss: 3.111451  [32000/50000]\n",
            "loss: 2.811255  [38400/50000]\n",
            "loss: 2.853654  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 26.1%, Avg loss: 3.108721 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 2.703062  [    0/50000]\n",
            "loss: 2.779516  [ 6400/50000]\n",
            "loss: 2.684442  [12800/50000]\n",
            "loss: 2.917083  [19200/50000]\n",
            "loss: 2.864120  [25600/50000]\n",
            "loss: 2.348037  [32000/50000]\n",
            "loss: 2.584197  [38400/50000]\n",
            "loss: 2.303941  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 26.2%, Avg loss: 3.098213 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 2.636320  [    0/50000]\n",
            "loss: 2.900558  [ 6400/50000]\n",
            "loss: 2.847045  [12800/50000]\n",
            "loss: 2.771784  [19200/50000]\n",
            "loss: 2.381222  [25600/50000]\n",
            "loss: 2.636765  [32000/50000]\n",
            "loss: 3.135346  [38400/50000]\n",
            "loss: 2.869196  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 26.0%, Avg loss: 3.115490 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 2.369507  [    0/50000]\n",
            "loss: 2.920161  [ 6400/50000]\n",
            "loss: 2.732287  [12800/50000]\n",
            "loss: 2.796798  [19200/50000]\n",
            "loss: 2.643232  [25600/50000]\n",
            "loss: 2.584449  [32000/50000]\n",
            "loss: 2.445315  [38400/50000]\n",
            "loss: 2.937597  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 26.7%, Avg loss: 3.084894 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 2.499294  [    0/50000]\n",
            "loss: 2.923777  [ 6400/50000]\n",
            "loss: 2.759799  [12800/50000]\n",
            "loss: 2.408989  [19200/50000]\n",
            "loss: 2.955006  [25600/50000]\n",
            "loss: 2.676384  [32000/50000]\n",
            "loss: 2.615787  [38400/50000]\n",
            "loss: 2.420688  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 26.8%, Avg loss: 3.113003 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 2.556568  [    0/50000]\n",
            "loss: 2.598723  [ 6400/50000]\n",
            "loss: 3.131037  [12800/50000]\n",
            "loss: 2.577521  [19200/50000]\n",
            "loss: 2.518054  [25600/50000]\n",
            "loss: 2.714751  [32000/50000]\n",
            "loss: 2.509734  [38400/50000]\n",
            "loss: 2.592090  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.1%, Avg loss: 3.084100 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 2.459109  [    0/50000]\n",
            "loss: 2.450787  [ 6400/50000]\n",
            "loss: 2.410272  [12800/50000]\n",
            "loss: 2.756112  [19200/50000]\n",
            "loss: 2.475803  [25600/50000]\n",
            "loss: 2.373059  [32000/50000]\n",
            "loss: 2.591361  [38400/50000]\n",
            "loss: 2.540424  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.1%, Avg loss: 3.065135 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 2.189086  [    0/50000]\n",
            "loss: 2.551776  [ 6400/50000]\n",
            "loss: 2.318485  [12800/50000]\n",
            "loss: 2.484341  [19200/50000]\n",
            "loss: 2.716649  [25600/50000]\n",
            "loss: 2.786221  [32000/50000]\n",
            "loss: 2.148428  [38400/50000]\n",
            "loss: 2.481215  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.0%, Avg loss: 3.072577 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 2.243406  [    0/50000]\n",
            "loss: 2.955457  [ 6400/50000]\n",
            "loss: 2.780731  [12800/50000]\n",
            "loss: 2.486590  [19200/50000]\n",
            "loss: 2.758907  [25600/50000]\n",
            "loss: 2.464009  [32000/50000]\n",
            "loss: 2.826880  [38400/50000]\n",
            "loss: 2.355154  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 26.5%, Avg loss: 3.087088 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 2.565784  [    0/50000]\n",
            "loss: 2.503350  [ 6400/50000]\n",
            "loss: 2.735896  [12800/50000]\n",
            "loss: 2.329174  [19200/50000]\n",
            "loss: 2.365572  [25600/50000]\n",
            "loss: 2.645164  [32000/50000]\n",
            "loss: 2.507972  [38400/50000]\n",
            "loss: 2.339734  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.3%, Avg loss: 3.081813 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 2.165887  [    0/50000]\n",
            "loss: 2.972559  [ 6400/50000]\n",
            "loss: 2.659818  [12800/50000]\n",
            "loss: 2.471207  [19200/50000]\n",
            "loss: 2.753113  [25600/50000]\n",
            "loss: 2.543861  [32000/50000]\n",
            "loss: 2.278094  [38400/50000]\n",
            "loss: 2.197911  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.0%, Avg loss: 3.084345 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 2.314467  [    0/50000]\n",
            "loss: 2.753579  [ 6400/50000]\n",
            "loss: 2.481118  [12800/50000]\n",
            "loss: 3.109574  [19200/50000]\n",
            "loss: 2.476143  [25600/50000]\n",
            "loss: 2.588756  [32000/50000]\n",
            "loss: 2.316052  [38400/50000]\n",
            "loss: 2.514812  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 26.5%, Avg loss: 3.084485 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 2.218326  [    0/50000]\n",
            "loss: 2.593183  [ 6400/50000]\n",
            "loss: 2.806015  [12800/50000]\n",
            "loss: 2.511190  [19200/50000]\n",
            "loss: 2.767168  [25600/50000]\n",
            "loss: 2.826068  [32000/50000]\n",
            "loss: 2.427277  [38400/50000]\n",
            "loss: 2.490929  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.3%, Avg loss: 3.072913 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 2.311698  [    0/50000]\n",
            "loss: 2.322927  [ 6400/50000]\n",
            "loss: 2.634863  [12800/50000]\n",
            "loss: 2.441900  [19200/50000]\n",
            "loss: 2.616225  [25600/50000]\n",
            "loss: 2.299137  [32000/50000]\n",
            "loss: 2.199369  [38400/50000]\n",
            "loss: 2.540348  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.8%, Avg loss: 3.057373 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 2.550125  [    0/50000]\n",
            "loss: 2.158471  [ 6400/50000]\n",
            "loss: 2.695787  [12800/50000]\n",
            "loss: 2.849011  [19200/50000]\n",
            "loss: 2.289729  [25600/50000]\n",
            "loss: 2.426379  [32000/50000]\n",
            "loss: 2.541497  [38400/50000]\n",
            "loss: 2.634070  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 26.8%, Avg loss: 3.081832 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 2.178231  [    0/50000]\n",
            "loss: 2.178294  [ 6400/50000]\n",
            "loss: 2.299582  [12800/50000]\n",
            "loss: 2.277117  [19200/50000]\n",
            "loss: 2.592123  [25600/50000]\n",
            "loss: 2.112937  [32000/50000]\n",
            "loss: 2.629412  [38400/50000]\n",
            "loss: 2.236423  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.8%, Avg loss: 3.043102 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 2.436237  [    0/50000]\n",
            "loss: 2.294119  [ 6400/50000]\n",
            "loss: 2.462379  [12800/50000]\n",
            "loss: 2.775410  [19200/50000]\n",
            "loss: 2.211811  [25600/50000]\n",
            "loss: 2.595931  [32000/50000]\n",
            "loss: 2.375956  [38400/50000]\n",
            "loss: 2.404753  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.5%, Avg loss: 3.063727 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 2.421347  [    0/50000]\n",
            "loss: 2.656556  [ 6400/50000]\n",
            "loss: 2.233977  [12800/50000]\n",
            "loss: 2.866804  [19200/50000]\n",
            "loss: 2.425369  [25600/50000]\n",
            "loss: 2.217505  [32000/50000]\n",
            "loss: 2.399374  [38400/50000]\n",
            "loss: 2.537848  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 26.8%, Avg loss: 3.082946 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 2.578104  [    0/50000]\n",
            "loss: 2.629167  [ 6400/50000]\n",
            "loss: 2.258811  [12800/50000]\n",
            "loss: 2.587949  [19200/50000]\n",
            "loss: 2.386029  [25600/50000]\n",
            "loss: 2.443712  [32000/50000]\n",
            "loss: 2.216716  [38400/50000]\n",
            "loss: 2.075757  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.6%, Avg loss: 3.056931 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 2.255105  [    0/50000]\n",
            "loss: 2.428658  [ 6400/50000]\n",
            "loss: 2.473845  [12800/50000]\n",
            "loss: 2.264976  [19200/50000]\n",
            "loss: 2.545781  [25600/50000]\n",
            "loss: 2.663266  [32000/50000]\n",
            "loss: 2.313354  [38400/50000]\n",
            "loss: 2.587727  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.7%, Avg loss: 3.047806 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 2.471263  [    0/50000]\n",
            "loss: 2.909277  [ 6400/50000]\n",
            "loss: 2.824264  [12800/50000]\n",
            "loss: 2.799375  [19200/50000]\n",
            "loss: 2.520338  [25600/50000]\n",
            "loss: 2.511818  [32000/50000]\n",
            "loss: 2.758009  [38400/50000]\n",
            "loss: 2.533356  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.8%, Avg loss: 3.058723 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 2.419856  [    0/50000]\n",
            "loss: 2.234007  [ 6400/50000]\n",
            "loss: 2.725179  [12800/50000]\n",
            "loss: 2.253551  [19200/50000]\n",
            "loss: 2.486526  [25600/50000]\n",
            "loss: 2.837834  [32000/50000]\n",
            "loss: 2.036533  [38400/50000]\n",
            "loss: 2.534285  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.0%, Avg loss: 3.051192 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 2.822895  [    0/50000]\n",
            "loss: 2.312626  [ 6400/50000]\n",
            "loss: 2.577714  [12800/50000]\n",
            "loss: 2.197070  [19200/50000]\n",
            "loss: 2.294347  [25600/50000]\n",
            "loss: 2.250501  [32000/50000]\n",
            "loss: 2.229971  [38400/50000]\n",
            "loss: 2.510055  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.3%, Avg loss: 3.066708 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 2.633647  [    0/50000]\n",
            "loss: 2.673652  [ 6400/50000]\n",
            "loss: 2.462635  [12800/50000]\n",
            "loss: 2.167917  [19200/50000]\n",
            "loss: 2.440204  [25600/50000]\n",
            "loss: 2.771521  [32000/50000]\n",
            "loss: 2.660359  [38400/50000]\n",
            "loss: 2.288233  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.9%, Avg loss: 3.048182 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 2.316817  [    0/50000]\n",
            "loss: 2.111484  [ 6400/50000]\n",
            "loss: 2.469533  [12800/50000]\n",
            "loss: 2.233417  [19200/50000]\n",
            "loss: 2.690972  [25600/50000]\n",
            "loss: 2.719680  [32000/50000]\n",
            "loss: 2.436076  [38400/50000]\n",
            "loss: 2.145130  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.7%, Avg loss: 3.082231 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 2.399107  [    0/50000]\n",
            "loss: 2.357263  [ 6400/50000]\n",
            "loss: 2.479057  [12800/50000]\n",
            "loss: 2.302410  [19200/50000]\n",
            "loss: 2.320657  [25600/50000]\n",
            "loss: 2.409739  [32000/50000]\n",
            "loss: 2.400193  [38400/50000]\n",
            "loss: 2.480148  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.3%, Avg loss: 3.073674 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 2.505646  [    0/50000]\n",
            "loss: 2.459154  [ 6400/50000]\n",
            "loss: 2.332797  [12800/50000]\n",
            "loss: 2.241558  [19200/50000]\n",
            "loss: 2.360806  [25600/50000]\n",
            "loss: 2.088651  [32000/50000]\n",
            "loss: 2.068488  [38400/50000]\n",
            "loss: 2.564068  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.6%, Avg loss: 3.082108 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 2.080629  [    0/50000]\n",
            "loss: 2.508185  [ 6400/50000]\n",
            "loss: 2.170858  [12800/50000]\n",
            "loss: 1.916637  [19200/50000]\n",
            "loss: 1.961966  [25600/50000]\n",
            "loss: 2.301425  [32000/50000]\n",
            "loss: 2.620142  [38400/50000]\n",
            "loss: 2.347697  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.0%, Avg loss: 3.059821 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 2.272052  [    0/50000]\n",
            "loss: 2.517175  [ 6400/50000]\n",
            "loss: 1.966061  [12800/50000]\n",
            "loss: 2.209094  [19200/50000]\n",
            "loss: 2.585699  [25600/50000]\n",
            "loss: 2.266795  [32000/50000]\n",
            "loss: 2.083548  [38400/50000]\n",
            "loss: 2.747068  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.1%, Avg loss: 3.075784 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 2.199924  [    0/50000]\n",
            "loss: 1.873802  [ 6400/50000]\n",
            "loss: 2.375276  [12800/50000]\n",
            "loss: 2.008334  [19200/50000]\n",
            "loss: 2.391617  [25600/50000]\n",
            "loss: 2.459682  [32000/50000]\n",
            "loss: 2.422463  [38400/50000]\n",
            "loss: 2.651446  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.1%, Avg loss: 3.076421 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 2.368927  [    0/50000]\n",
            "loss: 2.426590  [ 6400/50000]\n",
            "loss: 2.562660  [12800/50000]\n",
            "loss: 2.091521  [19200/50000]\n",
            "loss: 1.967991  [25600/50000]\n",
            "loss: 2.182082  [32000/50000]\n",
            "loss: 2.424635  [38400/50000]\n",
            "loss: 2.937978  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.5%, Avg loss: 3.058654 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 2.405252  [    0/50000]\n",
            "loss: 2.092947  [ 6400/50000]\n",
            "loss: 2.209533  [12800/50000]\n",
            "loss: 2.119459  [19200/50000]\n",
            "loss: 1.882331  [25600/50000]\n",
            "loss: 2.394202  [32000/50000]\n",
            "loss: 2.089893  [38400/50000]\n",
            "loss: 2.398974  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.9%, Avg loss: 3.081403 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 2.288397  [    0/50000]\n",
            "loss: 2.506630  [ 6400/50000]\n",
            "loss: 2.188430  [12800/50000]\n",
            "loss: 2.202635  [19200/50000]\n",
            "loss: 2.450551  [25600/50000]\n",
            "loss: 2.242741  [32000/50000]\n",
            "loss: 2.580494  [38400/50000]\n",
            "loss: 2.293414  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.3%, Avg loss: 3.078475 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 2.360339  [    0/50000]\n",
            "loss: 1.925637  [ 6400/50000]\n",
            "loss: 2.291203  [12800/50000]\n",
            "loss: 2.155844  [19200/50000]\n",
            "loss: 2.139958  [25600/50000]\n",
            "loss: 2.499464  [32000/50000]\n",
            "loss: 1.927602  [38400/50000]\n",
            "loss: 2.272607  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.9%, Avg loss: 3.086084 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 1.852143  [    0/50000]\n",
            "loss: 2.312434  [ 6400/50000]\n",
            "loss: 2.027061  [12800/50000]\n",
            "loss: 2.204489  [19200/50000]\n",
            "loss: 2.483150  [25600/50000]\n",
            "loss: 2.390686  [32000/50000]\n",
            "loss: 2.471091  [38400/50000]\n",
            "loss: 2.218002  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.5%, Avg loss: 3.077672 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 1.695878  [    0/50000]\n",
            "loss: 2.087619  [ 6400/50000]\n",
            "loss: 2.459990  [12800/50000]\n",
            "loss: 2.278753  [19200/50000]\n",
            "loss: 2.282943  [25600/50000]\n",
            "loss: 2.113474  [32000/50000]\n",
            "loss: 2.215386  [38400/50000]\n",
            "loss: 2.011604  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.3%, Avg loss: 3.085460 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 2.288064  [    0/50000]\n",
            "loss: 2.023943  [ 6400/50000]\n",
            "loss: 2.254757  [12800/50000]\n",
            "loss: 1.853744  [19200/50000]\n",
            "loss: 2.056107  [25600/50000]\n",
            "loss: 2.185005  [32000/50000]\n",
            "loss: 2.098234  [38400/50000]\n",
            "loss: 2.031752  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.6%, Avg loss: 3.083040 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 2.268164  [    0/50000]\n",
            "loss: 2.220495  [ 6400/50000]\n",
            "loss: 2.098561  [12800/50000]\n",
            "loss: 1.957446  [19200/50000]\n",
            "loss: 1.788769  [25600/50000]\n",
            "loss: 2.177691  [32000/50000]\n",
            "loss: 2.072521  [38400/50000]\n",
            "loss: 1.946995  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.8%, Avg loss: 3.115602 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 2.210592  [    0/50000]\n",
            "loss: 2.051530  [ 6400/50000]\n",
            "loss: 1.958109  [12800/50000]\n",
            "loss: 1.710124  [19200/50000]\n",
            "loss: 2.105936  [25600/50000]\n",
            "loss: 2.131450  [32000/50000]\n",
            "loss: 2.234225  [38400/50000]\n",
            "loss: 2.021059  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.7%, Avg loss: 3.095533 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 2.321557  [    0/50000]\n",
            "loss: 1.884505  [ 6400/50000]\n",
            "loss: 1.810336  [12800/50000]\n",
            "loss: 2.148396  [19200/50000]\n",
            "loss: 2.214397  [25600/50000]\n",
            "loss: 2.392155  [32000/50000]\n",
            "loss: 2.083547  [38400/50000]\n",
            "loss: 2.036422  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.7%, Avg loss: 3.095070 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 2.207584  [    0/50000]\n",
            "loss: 2.080232  [ 6400/50000]\n",
            "loss: 2.182843  [12800/50000]\n",
            "loss: 2.104897  [19200/50000]\n",
            "loss: 1.849526  [25600/50000]\n",
            "loss: 2.145244  [32000/50000]\n",
            "loss: 2.070886  [38400/50000]\n",
            "loss: 2.133608  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.1%, Avg loss: 3.112046 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 1.891641  [    0/50000]\n",
            "loss: 2.001688  [ 6400/50000]\n",
            "loss: 1.864956  [12800/50000]\n",
            "loss: 2.028690  [19200/50000]\n",
            "loss: 2.200895  [25600/50000]\n",
            "loss: 1.854462  [32000/50000]\n",
            "loss: 1.799498  [38400/50000]\n",
            "loss: 2.219511  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.3%, Avg loss: 3.091632 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 1.832373  [    0/50000]\n",
            "loss: 1.655113  [ 6400/50000]\n",
            "loss: 2.055552  [12800/50000]\n",
            "loss: 2.127621  [19200/50000]\n",
            "loss: 1.891477  [25600/50000]\n",
            "loss: 1.823333  [32000/50000]\n",
            "loss: 2.434790  [38400/50000]\n",
            "loss: 2.024987  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.7%, Avg loss: 3.114925 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 1.834994  [    0/50000]\n",
            "loss: 1.976644  [ 6400/50000]\n",
            "loss: 2.322736  [12800/50000]\n",
            "loss: 1.731230  [19200/50000]\n",
            "loss: 2.032358  [25600/50000]\n",
            "loss: 2.259235  [32000/50000]\n",
            "loss: 2.079464  [38400/50000]\n",
            "loss: 2.356297  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 29.0%, Avg loss: 3.102212 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 2.237940  [    0/50000]\n",
            "loss: 1.804307  [ 6400/50000]\n",
            "loss: 1.996642  [12800/50000]\n",
            "loss: 2.308520  [19200/50000]\n",
            "loss: 2.009682  [25600/50000]\n",
            "loss: 2.120306  [32000/50000]\n",
            "loss: 2.022420  [38400/50000]\n",
            "loss: 1.834685  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.6%, Avg loss: 3.120977 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 2.637180  [    0/50000]\n",
            "loss: 2.028532  [ 6400/50000]\n",
            "loss: 2.109535  [12800/50000]\n",
            "loss: 2.090773  [19200/50000]\n",
            "loss: 1.852371  [25600/50000]\n",
            "loss: 2.092828  [32000/50000]\n",
            "loss: 2.067846  [38400/50000]\n",
            "loss: 1.880842  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.8%, Avg loss: 3.107972 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 1.875681  [    0/50000]\n",
            "loss: 1.998944  [ 6400/50000]\n",
            "loss: 1.931233  [12800/50000]\n",
            "loss: 1.783936  [19200/50000]\n",
            "loss: 1.931436  [25600/50000]\n",
            "loss: 1.566801  [32000/50000]\n",
            "loss: 2.051599  [38400/50000]\n",
            "loss: 2.100455  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.5%, Avg loss: 3.136008 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "loss: 2.097203  [    0/50000]\n",
            "loss: 2.060469  [ 6400/50000]\n",
            "loss: 2.171063  [12800/50000]\n",
            "loss: 1.976653  [19200/50000]\n",
            "loss: 1.690998  [25600/50000]\n",
            "loss: 2.007785  [32000/50000]\n",
            "loss: 2.069634  [38400/50000]\n",
            "loss: 1.667663  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.0%, Avg loss: 3.146489 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "loss: 1.885154  [    0/50000]\n",
            "loss: 1.908832  [ 6400/50000]\n",
            "loss: 1.901011  [12800/50000]\n",
            "loss: 1.808150  [19200/50000]\n",
            "loss: 1.763463  [25600/50000]\n",
            "loss: 2.142688  [32000/50000]\n",
            "loss: 1.873616  [38400/50000]\n",
            "loss: 2.193344  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.4%, Avg loss: 3.165533 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "loss: 2.037316  [    0/50000]\n",
            "loss: 2.118617  [ 6400/50000]\n",
            "loss: 2.032624  [12800/50000]\n",
            "loss: 2.306603  [19200/50000]\n",
            "loss: 1.998029  [25600/50000]\n",
            "loss: 2.261021  [32000/50000]\n",
            "loss: 1.931677  [38400/50000]\n",
            "loss: 2.249978  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.6%, Avg loss: 3.143555 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "loss: 1.509102  [    0/50000]\n",
            "loss: 2.059200  [ 6400/50000]\n",
            "loss: 2.015563  [12800/50000]\n",
            "loss: 1.945709  [19200/50000]\n",
            "loss: 2.132471  [25600/50000]\n",
            "loss: 2.134314  [32000/50000]\n",
            "loss: 2.365155  [38400/50000]\n",
            "loss: 2.173635  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.4%, Avg loss: 3.146078 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "loss: 1.751862  [    0/50000]\n",
            "loss: 1.886433  [ 6400/50000]\n",
            "loss: 2.045798  [12800/50000]\n",
            "loss: 1.695952  [19200/50000]\n",
            "loss: 2.279334  [25600/50000]\n",
            "loss: 1.883095  [32000/50000]\n",
            "loss: 2.066241  [38400/50000]\n",
            "loss: 2.083750  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.8%, Avg loss: 3.175684 \n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "loss: 1.976326  [    0/50000]\n",
            "loss: 1.886657  [ 6400/50000]\n",
            "loss: 1.784276  [12800/50000]\n",
            "loss: 2.122635  [19200/50000]\n",
            "loss: 2.225636  [25600/50000]\n",
            "loss: 1.785695  [32000/50000]\n",
            "loss: 2.178649  [38400/50000]\n",
            "loss: 1.962388  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.7%, Avg loss: 3.161626 \n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "loss: 1.798614  [    0/50000]\n",
            "loss: 1.733831  [ 6400/50000]\n",
            "loss: 1.843943  [12800/50000]\n",
            "loss: 1.758856  [19200/50000]\n",
            "loss: 1.996741  [25600/50000]\n",
            "loss: 1.778982  [32000/50000]\n",
            "loss: 2.197112  [38400/50000]\n",
            "loss: 1.924687  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.6%, Avg loss: 3.171302 \n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "loss: 1.463917  [    0/50000]\n",
            "loss: 1.572056  [ 6400/50000]\n",
            "loss: 1.962000  [12800/50000]\n",
            "loss: 2.210882  [19200/50000]\n",
            "loss: 1.713173  [25600/50000]\n",
            "loss: 1.944405  [32000/50000]\n",
            "loss: 2.022925  [38400/50000]\n",
            "loss: 1.964866  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.6%, Avg loss: 3.169954 \n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "loss: 1.765392  [    0/50000]\n",
            "loss: 1.879382  [ 6400/50000]\n",
            "loss: 1.885212  [12800/50000]\n",
            "loss: 1.815876  [19200/50000]\n",
            "loss: 1.585117  [25600/50000]\n",
            "loss: 1.998631  [32000/50000]\n",
            "loss: 1.801871  [38400/50000]\n",
            "loss: 1.835593  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.0%, Avg loss: 3.246153 \n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "loss: 2.038090  [    0/50000]\n",
            "loss: 1.953323  [ 6400/50000]\n",
            "loss: 1.921628  [12800/50000]\n",
            "loss: 1.932343  [19200/50000]\n",
            "loss: 2.172510  [25600/50000]\n",
            "loss: 1.979268  [32000/50000]\n",
            "loss: 1.713259  [38400/50000]\n",
            "loss: 1.730863  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 29.1%, Avg loss: 3.162376 \n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "loss: 1.916973  [    0/50000]\n",
            "loss: 1.715034  [ 6400/50000]\n",
            "loss: 2.216679  [12800/50000]\n",
            "loss: 1.833971  [19200/50000]\n",
            "loss: 1.977989  [25600/50000]\n",
            "loss: 1.913592  [32000/50000]\n",
            "loss: 1.643043  [38400/50000]\n",
            "loss: 2.082647  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.9%, Avg loss: 3.232039 \n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "loss: 2.045667  [    0/50000]\n",
            "loss: 1.794954  [ 6400/50000]\n",
            "loss: 1.659058  [12800/50000]\n",
            "loss: 2.157710  [19200/50000]\n",
            "loss: 2.083437  [25600/50000]\n",
            "loss: 1.820930  [32000/50000]\n",
            "loss: 1.819882  [38400/50000]\n",
            "loss: 2.088273  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.1%, Avg loss: 3.199269 \n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "loss: 1.692334  [    0/50000]\n",
            "loss: 1.960318  [ 6400/50000]\n",
            "loss: 2.138258  [12800/50000]\n",
            "loss: 2.149884  [19200/50000]\n",
            "loss: 1.940193  [25600/50000]\n",
            "loss: 2.034080  [32000/50000]\n",
            "loss: 1.966865  [38400/50000]\n",
            "loss: 1.652146  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.1%, Avg loss: 3.228845 \n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "loss: 1.913052  [    0/50000]\n",
            "loss: 1.646234  [ 6400/50000]\n",
            "loss: 1.990485  [12800/50000]\n",
            "loss: 1.663759  [19200/50000]\n",
            "loss: 1.444365  [25600/50000]\n",
            "loss: 1.890349  [32000/50000]\n",
            "loss: 1.821276  [38400/50000]\n",
            "loss: 1.832670  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.5%, Avg loss: 3.234450 \n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "loss: 1.571221  [    0/50000]\n",
            "loss: 1.737890  [ 6400/50000]\n",
            "loss: 1.649280  [12800/50000]\n",
            "loss: 1.848731  [19200/50000]\n",
            "loss: 1.796626  [25600/50000]\n",
            "loss: 2.002505  [32000/50000]\n",
            "loss: 1.526483  [38400/50000]\n",
            "loss: 2.007434  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.1%, Avg loss: 3.236090 \n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "loss: 2.038398  [    0/50000]\n",
            "loss: 1.696780  [ 6400/50000]\n",
            "loss: 1.929722  [12800/50000]\n",
            "loss: 1.763885  [19200/50000]\n",
            "loss: 1.656275  [25600/50000]\n",
            "loss: 1.917620  [32000/50000]\n",
            "loss: 1.530777  [38400/50000]\n",
            "loss: 1.624263  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.4%, Avg loss: 3.222494 \n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "loss: 1.907981  [    0/50000]\n",
            "loss: 1.600501  [ 6400/50000]\n",
            "loss: 1.751163  [12800/50000]\n",
            "loss: 2.182840  [19200/50000]\n",
            "loss: 1.621463  [25600/50000]\n",
            "loss: 1.989157  [32000/50000]\n",
            "loss: 1.692444  [38400/50000]\n",
            "loss: 1.633808  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.7%, Avg loss: 3.229278 \n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "loss: 1.630221  [    0/50000]\n",
            "loss: 1.685225  [ 6400/50000]\n",
            "loss: 1.712549  [12800/50000]\n",
            "loss: 1.963443  [19200/50000]\n",
            "loss: 1.527113  [25600/50000]\n",
            "loss: 1.583833  [32000/50000]\n",
            "loss: 1.732967  [38400/50000]\n",
            "loss: 1.711025  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.4%, Avg loss: 3.257695 \n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "loss: 1.566721  [    0/50000]\n",
            "loss: 1.475699  [ 6400/50000]\n",
            "loss: 1.740286  [12800/50000]\n",
            "loss: 1.615679  [19200/50000]\n",
            "loss: 1.557903  [25600/50000]\n",
            "loss: 1.766448  [32000/50000]\n",
            "loss: 1.590443  [38400/50000]\n",
            "loss: 1.949923  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.5%, Avg loss: 3.234836 \n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "loss: 1.832515  [    0/50000]\n",
            "loss: 1.694277  [ 6400/50000]\n",
            "loss: 1.519417  [12800/50000]\n",
            "loss: 1.848017  [19200/50000]\n",
            "loss: 1.688546  [25600/50000]\n",
            "loss: 1.723046  [32000/50000]\n",
            "loss: 2.143152  [38400/50000]\n",
            "loss: 1.644771  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.5%, Avg loss: 3.278199 \n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "loss: 1.726058  [    0/50000]\n",
            "loss: 1.642839  [ 6400/50000]\n",
            "loss: 1.883529  [12800/50000]\n",
            "loss: 1.861639  [19200/50000]\n",
            "loss: 1.444703  [25600/50000]\n",
            "loss: 1.980224  [32000/50000]\n",
            "loss: 1.396254  [38400/50000]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-205-e830235bd1c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-203-726ac0365305>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2729\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2730\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tobytes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2731\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2732\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2733\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7T5-xVWY9P9"
      },
      "source": [
        "#     29%   ."
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxqp6USRLcxh"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class resblock(nn.Module):\n",
        "    def __init__(self, ch_in, ch_out, stride):\n",
        "        super(resblock, self).__init__()\n",
        "        self.conv_1 = nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=stride, padding=1)\n",
        "        self.bn_1 = nn.BatchNorm2d(ch_out)\n",
        "        self.conv_2 = nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn_2 = nn.BatchNorm2d(ch_out)\n",
        "        self.ch_in, self.ch_out, self.stride = ch_in, ch_out, stride\n",
        "        self.ch_trans = nn.Sequential()\n",
        "\n",
        "        if ch_in != ch_out:\n",
        "            self.ch_trans = nn.Sequential(\n",
        "                nn.Conv2d(ch_in, ch_out, kernel_size=1, stride=stride)\n",
        "            )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x_pro = F.relu(self.bn_1(self.conv_1(x)))\n",
        "        x_pro = self.bn_2(self.conv_2(x_pro))\n",
        "\n",
        "        x_ch = self.ch_trans(x)\n",
        "        out = x_pro + x_ch\n",
        "\n",
        "        return out"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhmrcoNfSVIM"
      },
      "source": [
        "class resnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(resnet, self).__init__()\n",
        "        self.conv_1 = nn.Sequential(\n",
        "          nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "          nn.BatchNorm2d(64)\n",
        "\n",
        "\n",
        "        )\n",
        "        self.block1 = resblock(64, 128, 2)\n",
        "        self.block2 = resblock(128, 256, 2)\n",
        "        self.block3 = resblock(256, 512, 1)  \n",
        "        self.block4 = resblock(512, 512, 1)\n",
        "        self.outlayer = nn.Linear(512, 100)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 3, 32, 32)\n",
        "        x = F.relu(self.conv_1(x))\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)  \n",
        "        x = self.block4(x)\n",
        "        x = F.adaptive_avg_pool2d(x, [1,1])\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        result = self.outlayer(x)\n",
        "\n",
        "        return result"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULzZ1k0qVRDG"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3mimrorTzNa"
      },
      "source": [
        "device = torch.device('cuda')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvg2slH1T3PL"
      },
      "source": [
        "net = resnet()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeS9UBwAT3SX"
      },
      "source": [
        "net = net.to(device)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zPJWs4XcUlR"
      },
      "source": [
        "# RuntimeError: CUDA error: device-side assert triggered\n",
        "# CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
        "# For debugging consider passing CUDA_ LAUNCH_ BLOCKING=1.\n",
        "#    "
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPmzfoKsT3Vh",
        "outputId": "15597ae1-03fc-4d83-a5aa-d06c8ec861fb"
      },
      "source": [
        "image, label = train_dataset[0]\n",
        "image.shape"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z48Y6DKdXghH"
      },
      "source": [
        "image = image.view(-1, 3, 32, 32)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuYCCK1BT3Yr"
      },
      "source": [
        "conv_1 = nn.Sequential(\n",
        "          nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "          nn.BatchNorm2d(64)\n",
        "\n",
        "\n",
        "        )"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKlQR7gdVsYb"
      },
      "source": [
        "x = conv_1(image)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2z8QW4NXp2G",
        "outputId": "7c7e5ec5-1435-4c8b-f117-f7da7de1af91"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImGX9jJHX3gs"
      },
      "source": [
        "block1 = resblock(64, 128, 2)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmnEimkLX7I5"
      },
      "source": [
        "x = block1(x)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFgOHOKgYDC5",
        "outputId": "7136d89c-072e-43f4-b301-2aa3db141212"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 128, 16, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nB6TwufYRnO"
      },
      "source": [
        "block2 = resblock(128, 256, 2)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGoiPYRTYTLW"
      },
      "source": [
        "x = block2(x)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izts1I3qYW6m",
        "outputId": "70345e08-9c6b-4bec-be5d-0b0708aad57d"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 256, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGPt2Dh6Yav6"
      },
      "source": [
        "block3 = resblock(256, 512, 1) "
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zQj6tzSZU88"
      },
      "source": [
        "x = block3(x)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siKaX2GzZZGS",
        "outputId": "291c8742-8bbb-4274-a4ef-1ec1a5c46ff4"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtWKGZEGZd2E"
      },
      "source": [
        "block4 = resblock(512, 512, 1)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs9HiKsIZiO0"
      },
      "source": [
        "x = block4(x)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9kJsRdXZiXc",
        "outputId": "269adbb1-c592-4a36-ebde-c2a982c7c2d6"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjwNnsSlZiao"
      },
      "source": [
        "x = F.adaptive_avg_pool2d(x, [1,1])"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSeMDykHZidf",
        "outputId": "e46144f2-7a83-4d40-c192-3693a362296d"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94fNu6b2ZvIi",
        "outputId": "3482a0ef-f80f-42ed-8e83-a19eefe4554a"
      },
      "source": [
        "x.size"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18MolVXQZvL7"
      },
      "source": [
        "x = x.reshape(x.size(0), -1)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8YyYQtSZvuf"
      },
      "source": [
        "outlayer = nn.Linear(512, 100)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRcYSzyRZvxk"
      },
      "source": [
        "x = outlayer(x)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3HgZ45vbSSc",
        "outputId": "5f46e5cd-99a7-4d00-9b12-db07cd2384e8"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFPY7SIKdBan"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIyXkuPlLXG7",
        "outputId": "b85601fa-3b4a-49b1-f10c-e8e3e0ce2031"
      },
      "source": [
        "epochs = 100\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_loader, net, loss_fn, optimizer)\n",
        "    test(test_loader, net, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 4.679064  [    0/50000]\n",
            "loss: 3.915469  [ 6400/50000]\n",
            "loss: 3.928963  [12800/50000]\n",
            "loss: 3.405168  [19200/50000]\n",
            "loss: 3.419940  [25600/50000]\n",
            "loss: 3.479933  [32000/50000]\n",
            "loss: 3.294418  [38400/50000]\n",
            "loss: 3.168612  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 17.2%, Avg loss: 3.615731 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 3.000235  [    0/50000]\n",
            "loss: 2.885749  [ 6400/50000]\n",
            "loss: 2.850346  [12800/50000]\n",
            "loss: 2.708573  [19200/50000]\n",
            "loss: 2.651639  [25600/50000]\n",
            "loss: 2.850076  [32000/50000]\n",
            "loss: 2.692066  [38400/50000]\n",
            "loss: 2.785685  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 26.3%, Avg loss: 2.990624 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.639330  [    0/50000]\n",
            "loss: 2.849676  [ 6400/50000]\n",
            "loss: 2.180912  [12800/50000]\n",
            "loss: 2.807862  [19200/50000]\n",
            "loss: 2.316794  [25600/50000]\n",
            "loss: 2.493722  [32000/50000]\n",
            "loss: 2.153420  [38400/50000]\n",
            "loss: 2.760375  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.9%, Avg loss: 2.384634 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 2.310563  [    0/50000]\n",
            "loss: 2.067063  [ 6400/50000]\n",
            "loss: 2.350365  [12800/50000]\n",
            "loss: 2.061280  [19200/50000]\n",
            "loss: 2.099692  [25600/50000]\n",
            "loss: 2.261014  [32000/50000]\n",
            "loss: 1.983410  [38400/50000]\n",
            "loss: 2.089733  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 43.3%, Avg loss: 2.163460 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.608103  [    0/50000]\n",
            "loss: 2.574931  [ 6400/50000]\n",
            "loss: 2.159415  [12800/50000]\n",
            "loss: 2.157871  [19200/50000]\n",
            "loss: 1.825394  [25600/50000]\n",
            "loss: 1.812847  [32000/50000]\n",
            "loss: 2.000683  [38400/50000]\n",
            "loss: 2.093920  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 35.9%, Avg loss: 2.609938 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.559646  [    0/50000]\n",
            "loss: 1.820359  [ 6400/50000]\n",
            "loss: 1.653208  [12800/50000]\n",
            "loss: 1.422277  [19200/50000]\n",
            "loss: 1.752094  [25600/50000]\n",
            "loss: 1.701718  [32000/50000]\n",
            "loss: 1.742709  [38400/50000]\n",
            "loss: 2.025844  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 45.9%, Avg loss: 2.016299 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.275637  [    0/50000]\n",
            "loss: 1.254228  [ 6400/50000]\n",
            "loss: 1.316943  [12800/50000]\n",
            "loss: 1.515566  [19200/50000]\n",
            "loss: 1.588158  [25600/50000]\n",
            "loss: 1.597996  [32000/50000]\n",
            "loss: 1.680459  [38400/50000]\n",
            "loss: 1.758019  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 46.9%, Avg loss: 1.977866 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.526082  [    0/50000]\n",
            "loss: 1.289789  [ 6400/50000]\n",
            "loss: 1.361249  [12800/50000]\n",
            "loss: 1.255454  [19200/50000]\n",
            "loss: 1.454672  [25600/50000]\n",
            "loss: 1.459630  [32000/50000]\n",
            "loss: 1.193202  [38400/50000]\n",
            "loss: 1.295267  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 45.8%, Avg loss: 2.139145 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.235700  [    0/50000]\n",
            "loss: 1.137335  [ 6400/50000]\n",
            "loss: 1.001604  [12800/50000]\n",
            "loss: 1.167396  [19200/50000]\n",
            "loss: 1.226114  [25600/50000]\n",
            "loss: 1.183419  [32000/50000]\n",
            "loss: 1.164826  [38400/50000]\n",
            "loss: 1.493804  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 51.1%, Avg loss: 1.807751 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.320109  [    0/50000]\n",
            "loss: 0.900825  [ 6400/50000]\n",
            "loss: 1.402177  [12800/50000]\n",
            "loss: 1.168312  [19200/50000]\n",
            "loss: 1.277973  [25600/50000]\n",
            "loss: 1.140832  [32000/50000]\n",
            "loss: 1.258565  [38400/50000]\n",
            "loss: 1.226502  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 52.3%, Avg loss: 1.781879 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.892924  [    0/50000]\n",
            "loss: 0.879015  [ 6400/50000]\n",
            "loss: 0.825050  [12800/50000]\n",
            "loss: 0.737614  [19200/50000]\n",
            "loss: 0.920353  [25600/50000]\n",
            "loss: 1.580142  [32000/50000]\n",
            "loss: 1.089680  [38400/50000]\n",
            "loss: 0.848942  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 49.4%, Avg loss: 1.964955 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.843733  [    0/50000]\n",
            "loss: 0.935322  [ 6400/50000]\n",
            "loss: 0.589606  [12800/50000]\n",
            "loss: 0.829421  [19200/50000]\n",
            "loss: 0.918883  [25600/50000]\n",
            "loss: 0.977029  [32000/50000]\n",
            "loss: 0.698100  [38400/50000]\n",
            "loss: 0.876769  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 52.2%, Avg loss: 1.834068 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.626705  [    0/50000]\n",
            "loss: 0.559942  [ 6400/50000]\n",
            "loss: 0.874369  [12800/50000]\n",
            "loss: 0.484252  [19200/50000]\n",
            "loss: 0.509724  [25600/50000]\n",
            "loss: 0.814532  [32000/50000]\n",
            "loss: 0.712119  [38400/50000]\n",
            "loss: 0.679298  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 55.0%, Avg loss: 1.713602 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.448289  [    0/50000]\n",
            "loss: 0.379941  [ 6400/50000]\n",
            "loss: 0.601107  [12800/50000]\n",
            "loss: 0.615096  [19200/50000]\n",
            "loss: 0.456017  [25600/50000]\n",
            "loss: 0.390406  [32000/50000]\n",
            "loss: 0.569233  [38400/50000]\n",
            "loss: 0.677900  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 50.0%, Avg loss: 2.036770 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.700163  [    0/50000]\n",
            "loss: 0.354426  [ 6400/50000]\n",
            "loss: 0.427438  [12800/50000]\n",
            "loss: 0.383084  [19200/50000]\n",
            "loss: 0.453669  [25600/50000]\n",
            "loss: 0.529213  [32000/50000]\n",
            "loss: 0.463609  [38400/50000]\n",
            "loss: 0.655782  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 53.2%, Avg loss: 1.848540 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.446360  [    0/50000]\n",
            "loss: 0.274906  [ 6400/50000]\n",
            "loss: 0.227757  [12800/50000]\n",
            "loss: 0.271136  [19200/50000]\n",
            "loss: 0.568289  [25600/50000]\n",
            "loss: 0.352306  [32000/50000]\n",
            "loss: 0.302619  [38400/50000]\n",
            "loss: 0.357149  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 53.9%, Avg loss: 1.881673 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.305365  [    0/50000]\n",
            "loss: 0.185077  [ 6400/50000]\n",
            "loss: 0.178674  [12800/50000]\n",
            "loss: 0.184295  [19200/50000]\n",
            "loss: 0.221996  [25600/50000]\n",
            "loss: 0.342145  [32000/50000]\n",
            "loss: 0.269060  [38400/50000]\n",
            "loss: 0.219277  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 54.1%, Avg loss: 1.917899 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.206993  [    0/50000]\n",
            "loss: 0.187878  [ 6400/50000]\n",
            "loss: 0.151561  [12800/50000]\n",
            "loss: 0.153320  [19200/50000]\n",
            "loss: 0.128189  [25600/50000]\n",
            "loss: 0.211994  [32000/50000]\n",
            "loss: 0.195414  [38400/50000]\n",
            "loss: 0.166748  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 54.2%, Avg loss: 1.877880 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.076878  [    0/50000]\n",
            "loss: 0.152177  [ 6400/50000]\n",
            "loss: 0.087271  [12800/50000]\n",
            "loss: 0.076153  [19200/50000]\n",
            "loss: 0.117980  [25600/50000]\n",
            "loss: 0.172516  [32000/50000]\n",
            "loss: 0.128822  [38400/50000]\n",
            "loss: 0.132581  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 54.9%, Avg loss: 1.934400 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.115703  [    0/50000]\n",
            "loss: 0.084617  [ 6400/50000]\n",
            "loss: 0.050619  [12800/50000]\n",
            "loss: 0.054226  [19200/50000]\n",
            "loss: 0.048908  [25600/50000]\n",
            "loss: 0.070787  [32000/50000]\n",
            "loss: 0.063901  [38400/50000]\n",
            "loss: 0.069777  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 56.2%, Avg loss: 1.835017 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.044413  [    0/50000]\n",
            "loss: 0.042669  [ 6400/50000]\n",
            "loss: 0.041049  [12800/50000]\n",
            "loss: 0.044998  [19200/50000]\n",
            "loss: 0.046895  [25600/50000]\n",
            "loss: 0.069781  [32000/50000]\n",
            "loss: 0.044175  [38400/50000]\n",
            "loss: 0.033651  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 56.7%, Avg loss: 1.821766 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.042036  [    0/50000]\n",
            "loss: 0.025811  [ 6400/50000]\n",
            "loss: 0.056049  [12800/50000]\n",
            "loss: 0.033609  [19200/50000]\n",
            "loss: 0.025361  [25600/50000]\n",
            "loss: 0.028056  [32000/50000]\n",
            "loss: 0.083244  [38400/50000]\n",
            "loss: 0.026011  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.6%, Avg loss: 1.825958 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.028513  [    0/50000]\n",
            "loss: 0.013231  [ 6400/50000]\n",
            "loss: 0.021850  [12800/50000]\n",
            "loss: 0.032201  [19200/50000]\n",
            "loss: 0.030877  [25600/50000]\n",
            "loss: 0.019553  [32000/50000]\n",
            "loss: 0.029379  [38400/50000]\n",
            "loss: 0.015123  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.9%, Avg loss: 1.796449 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.020815  [    0/50000]\n",
            "loss: 0.013682  [ 6400/50000]\n",
            "loss: 0.023710  [12800/50000]\n",
            "loss: 0.103955  [19200/50000]\n",
            "loss: 0.014314  [25600/50000]\n",
            "loss: 0.027388  [32000/50000]\n",
            "loss: 0.022166  [38400/50000]\n",
            "loss: 0.010774  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.6%, Avg loss: 1.806001 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.072948  [    0/50000]\n",
            "loss: 0.018730  [ 6400/50000]\n",
            "loss: 0.046760  [12800/50000]\n",
            "loss: 0.010747  [19200/50000]\n",
            "loss: 0.012744  [25600/50000]\n",
            "loss: 0.010655  [32000/50000]\n",
            "loss: 0.012866  [38400/50000]\n",
            "loss: 0.017436  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.6%, Avg loss: 1.816658 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.009578  [    0/50000]\n",
            "loss: 0.013036  [ 6400/50000]\n",
            "loss: 0.009808  [12800/50000]\n",
            "loss: 0.015500  [19200/50000]\n",
            "loss: 0.014058  [25600/50000]\n",
            "loss: 0.014525  [32000/50000]\n",
            "loss: 0.008839  [38400/50000]\n",
            "loss: 0.080751  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 1.830540 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.008372  [    0/50000]\n",
            "loss: 0.013555  [ 6400/50000]\n",
            "loss: 0.009412  [12800/50000]\n",
            "loss: 0.009635  [19200/50000]\n",
            "loss: 0.010437  [25600/50000]\n",
            "loss: 0.010679  [32000/50000]\n",
            "loss: 0.012724  [38400/50000]\n",
            "loss: 0.009282  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.9%, Avg loss: 1.844734 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.010692  [    0/50000]\n",
            "loss: 0.010163  [ 6400/50000]\n",
            "loss: 0.013493  [12800/50000]\n",
            "loss: 0.006915  [19200/50000]\n",
            "loss: 0.010824  [25600/50000]\n",
            "loss: 0.006638  [32000/50000]\n",
            "loss: 0.008037  [38400/50000]\n",
            "loss: 0.008287  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.5%, Avg loss: 1.845181 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.008741  [    0/50000]\n",
            "loss: 0.007511  [ 6400/50000]\n",
            "loss: 0.011307  [12800/50000]\n",
            "loss: 0.006049  [19200/50000]\n",
            "loss: 0.012909  [25600/50000]\n",
            "loss: 0.012765  [32000/50000]\n",
            "loss: 0.006985  [38400/50000]\n",
            "loss: 0.010225  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 1.882019 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.006562  [    0/50000]\n",
            "loss: 0.005184  [ 6400/50000]\n",
            "loss: 0.012804  [12800/50000]\n",
            "loss: 0.005703  [19200/50000]\n",
            "loss: 0.013208  [25600/50000]\n",
            "loss: 0.008386  [32000/50000]\n",
            "loss: 0.009535  [38400/50000]\n",
            "loss: 0.007238  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 1.868335 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.006462  [    0/50000]\n",
            "loss: 0.011382  [ 6400/50000]\n",
            "loss: 0.007361  [12800/50000]\n",
            "loss: 0.008449  [19200/50000]\n",
            "loss: 0.006324  [25600/50000]\n",
            "loss: 0.010835  [32000/50000]\n",
            "loss: 0.008886  [38400/50000]\n",
            "loss: 0.007855  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.1%, Avg loss: 1.857340 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.005972  [    0/50000]\n",
            "loss: 0.006989  [ 6400/50000]\n",
            "loss: 0.007825  [12800/50000]\n",
            "loss: 0.007575  [19200/50000]\n",
            "loss: 0.006961  [25600/50000]\n",
            "loss: 0.006142  [32000/50000]\n",
            "loss: 0.006425  [38400/50000]\n",
            "loss: 0.006416  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.1%, Avg loss: 1.870185 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.004300  [    0/50000]\n",
            "loss: 0.006265  [ 6400/50000]\n",
            "loss: 0.005785  [12800/50000]\n",
            "loss: 0.005303  [19200/50000]\n",
            "loss: 0.005158  [25600/50000]\n",
            "loss: 0.005115  [32000/50000]\n",
            "loss: 0.005835  [38400/50000]\n",
            "loss: 0.005057  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.0%, Avg loss: 1.878814 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.005567  [    0/50000]\n",
            "loss: 0.013438  [ 6400/50000]\n",
            "loss: 0.004017  [12800/50000]\n",
            "loss: 0.004578  [19200/50000]\n",
            "loss: 0.005509  [25600/50000]\n",
            "loss: 0.004330  [32000/50000]\n",
            "loss: 0.005931  [38400/50000]\n",
            "loss: 0.006102  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.2%, Avg loss: 1.889638 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.005517  [    0/50000]\n",
            "loss: 0.004788  [ 6400/50000]\n",
            "loss: 0.011873  [12800/50000]\n",
            "loss: 0.007182  [19200/50000]\n",
            "loss: 0.006446  [25600/50000]\n",
            "loss: 0.008046  [32000/50000]\n",
            "loss: 0.005142  [38400/50000]\n",
            "loss: 0.005879  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.1%, Avg loss: 1.893088 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.004106  [    0/50000]\n",
            "loss: 0.004272  [ 6400/50000]\n",
            "loss: 0.005244  [12800/50000]\n",
            "loss: 0.004755  [19200/50000]\n",
            "loss: 0.004788  [25600/50000]\n",
            "loss: 0.005373  [32000/50000]\n",
            "loss: 0.005780  [38400/50000]\n",
            "loss: 0.004796  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.0%, Avg loss: 1.888810 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.004197  [    0/50000]\n",
            "loss: 0.003571  [ 6400/50000]\n",
            "loss: 0.005175  [12800/50000]\n",
            "loss: 0.004812  [19200/50000]\n",
            "loss: 0.005172  [25600/50000]\n",
            "loss: 0.003599  [32000/50000]\n",
            "loss: 0.004777  [38400/50000]\n",
            "loss: 0.007357  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.8%, Avg loss: 1.894704 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.005225  [    0/50000]\n",
            "loss: 0.004218  [ 6400/50000]\n",
            "loss: 0.005622  [12800/50000]\n",
            "loss: 0.005453  [19200/50000]\n",
            "loss: 0.006510  [25600/50000]\n",
            "loss: 0.004543  [32000/50000]\n",
            "loss: 0.005363  [38400/50000]\n",
            "loss: 0.004479  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.1%, Avg loss: 1.903902 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.004518  [    0/50000]\n",
            "loss: 0.004734  [ 6400/50000]\n",
            "loss: 0.004921  [12800/50000]\n",
            "loss: 0.004620  [19200/50000]\n",
            "loss: 0.004913  [25600/50000]\n",
            "loss: 0.003505  [32000/50000]\n",
            "loss: 0.004374  [38400/50000]\n",
            "loss: 0.005109  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.0%, Avg loss: 1.911484 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.003743  [    0/50000]\n",
            "loss: 0.003434  [ 6400/50000]\n",
            "loss: 0.007529  [12800/50000]\n",
            "loss: 0.003287  [19200/50000]\n",
            "loss: 0.003295  [25600/50000]\n",
            "loss: 0.004615  [32000/50000]\n",
            "loss: 0.003599  [38400/50000]\n",
            "loss: 0.009091  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 1.915436 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.004123  [    0/50000]\n",
            "loss: 0.003767  [ 6400/50000]\n",
            "loss: 0.003285  [12800/50000]\n",
            "loss: 0.005524  [19200/50000]\n",
            "loss: 0.005261  [25600/50000]\n",
            "loss: 0.004156  [32000/50000]\n",
            "loss: 0.005350  [38400/50000]\n",
            "loss: 0.005094  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 1.924834 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.004108  [    0/50000]\n",
            "loss: 0.007019  [ 6400/50000]\n",
            "loss: 0.004712  [12800/50000]\n",
            "loss: 0.004286  [19200/50000]\n",
            "loss: 0.002939  [25600/50000]\n",
            "loss: 0.004501  [32000/50000]\n",
            "loss: 0.003813  [38400/50000]\n",
            "loss: 0.003388  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.1%, Avg loss: 1.919267 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.003894  [    0/50000]\n",
            "loss: 0.006381  [ 6400/50000]\n",
            "loss: 0.004121  [12800/50000]\n",
            "loss: 0.003653  [19200/50000]\n",
            "loss: 0.004621  [25600/50000]\n",
            "loss: 0.003692  [32000/50000]\n",
            "loss: 0.005134  [38400/50000]\n",
            "loss: 0.002997  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.0%, Avg loss: 1.921211 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.003871  [    0/50000]\n",
            "loss: 0.004414  [ 6400/50000]\n",
            "loss: 0.002888  [12800/50000]\n",
            "loss: 0.002806  [19200/50000]\n",
            "loss: 0.003316  [25600/50000]\n",
            "loss: 0.002972  [32000/50000]\n",
            "loss: 0.002752  [38400/50000]\n",
            "loss: 0.003794  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.9%, Avg loss: 1.931474 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.003240  [    0/50000]\n",
            "loss: 0.003747  [ 6400/50000]\n",
            "loss: 0.003315  [12800/50000]\n",
            "loss: 0.004434  [19200/50000]\n",
            "loss: 0.003281  [25600/50000]\n",
            "loss: 0.003680  [32000/50000]\n",
            "loss: 0.005614  [38400/50000]\n",
            "loss: 0.002830  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.0%, Avg loss: 1.928049 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.003205  [    0/50000]\n",
            "loss: 0.003447  [ 6400/50000]\n",
            "loss: 0.003943  [12800/50000]\n",
            "loss: 0.002408  [19200/50000]\n",
            "loss: 0.002522  [25600/50000]\n",
            "loss: 0.002608  [32000/50000]\n",
            "loss: 0.003175  [38400/50000]\n",
            "loss: 0.002391  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.9%, Avg loss: 1.933900 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.002383  [    0/50000]\n",
            "loss: 0.003637  [ 6400/50000]\n",
            "loss: 0.002831  [12800/50000]\n",
            "loss: 0.005670  [19200/50000]\n",
            "loss: 0.003468  [25600/50000]\n",
            "loss: 0.002912  [32000/50000]\n",
            "loss: 0.003194  [38400/50000]\n",
            "loss: 0.003087  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.0%, Avg loss: 1.933807 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.003045  [    0/50000]\n",
            "loss: 0.004269  [ 6400/50000]\n",
            "loss: 0.003071  [12800/50000]\n",
            "loss: 0.002854  [19200/50000]\n",
            "loss: 0.003776  [25600/50000]\n",
            "loss: 0.003149  [32000/50000]\n",
            "loss: 0.002704  [38400/50000]\n",
            "loss: 0.002426  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.9%, Avg loss: 1.935464 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.002606  [    0/50000]\n",
            "loss: 0.002954  [ 6400/50000]\n",
            "loss: 0.002452  [12800/50000]\n",
            "loss: 0.003391  [19200/50000]\n",
            "loss: 0.003569  [25600/50000]\n",
            "loss: 0.002048  [32000/50000]\n",
            "loss: 0.003091  [38400/50000]\n",
            "loss: 0.004743  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.9%, Avg loss: 1.948681 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.002609  [    0/50000]\n",
            "loss: 0.003319  [ 6400/50000]\n",
            "loss: 0.004119  [12800/50000]\n",
            "loss: 0.001755  [19200/50000]\n",
            "loss: 0.003514  [25600/50000]\n",
            "loss: 0.002891  [32000/50000]\n",
            "loss: 0.002529  [38400/50000]\n",
            "loss: 0.003042  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.0%, Avg loss: 1.946773 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 0.002356  [    0/50000]\n",
            "loss: 0.002138  [ 6400/50000]\n",
            "loss: 0.003258  [12800/50000]\n",
            "loss: 0.003708  [19200/50000]\n",
            "loss: 0.002921  [25600/50000]\n",
            "loss: 0.002220  [32000/50000]\n",
            "loss: 0.003575  [38400/50000]\n",
            "loss: 0.002422  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.9%, Avg loss: 1.951525 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 0.001902  [    0/50000]\n",
            "loss: 0.003649  [ 6400/50000]\n",
            "loss: 0.002824  [12800/50000]\n",
            "loss: 0.003706  [19200/50000]\n",
            "loss: 0.002543  [25600/50000]\n",
            "loss: 0.002261  [32000/50000]\n",
            "loss: 0.002297  [38400/50000]\n",
            "loss: 0.002834  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.0%, Avg loss: 1.951189 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 0.002216  [    0/50000]\n",
            "loss: 0.004158  [ 6400/50000]\n",
            "loss: 0.044055  [12800/50000]\n",
            "loss: 0.002222  [19200/50000]\n",
            "loss: 0.002507  [25600/50000]\n",
            "loss: 0.002243  [32000/50000]\n",
            "loss: 0.001632  [38400/50000]\n",
            "loss: 0.002637  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.9%, Avg loss: 1.952486 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 0.002228  [    0/50000]\n",
            "loss: 0.002361  [ 6400/50000]\n",
            "loss: 0.002329  [12800/50000]\n",
            "loss: 0.002672  [19200/50000]\n",
            "loss: 0.002123  [25600/50000]\n",
            "loss: 0.001926  [32000/50000]\n",
            "loss: 0.002550  [38400/50000]\n",
            "loss: 0.003226  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.0%, Avg loss: 1.957157 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 0.002029  [    0/50000]\n",
            "loss: 0.002141  [ 6400/50000]\n",
            "loss: 0.001910  [12800/50000]\n",
            "loss: 0.002669  [19200/50000]\n",
            "loss: 0.002449  [25600/50000]\n",
            "loss: 0.002170  [32000/50000]\n",
            "loss: 0.002348  [38400/50000]\n",
            "loss: 0.048925  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.0%, Avg loss: 1.961914 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 0.002556  [    0/50000]\n",
            "loss: 0.002372  [ 6400/50000]\n",
            "loss: 0.002602  [12800/50000]\n",
            "loss: 0.002276  [19200/50000]\n",
            "loss: 0.002887  [25600/50000]\n",
            "loss: 0.002732  [32000/50000]\n",
            "loss: 0.001726  [38400/50000]\n",
            "loss: 0.002679  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.8%, Avg loss: 1.967228 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 0.001917  [    0/50000]\n",
            "loss: 0.002042  [ 6400/50000]\n",
            "loss: 0.002406  [12800/50000]\n",
            "loss: 0.001886  [19200/50000]\n",
            "loss: 0.001940  [25600/50000]\n",
            "loss: 0.002058  [32000/50000]\n",
            "loss: 0.002053  [38400/50000]\n",
            "loss: 0.002319  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.9%, Avg loss: 1.968277 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 0.002475  [    0/50000]\n",
            "loss: 0.002128  [ 6400/50000]\n",
            "loss: 0.002138  [12800/50000]\n",
            "loss: 0.001730  [19200/50000]\n",
            "loss: 0.001873  [25600/50000]\n",
            "loss: 0.002305  [32000/50000]\n",
            "loss: 0.002034  [38400/50000]\n",
            "loss: 0.002144  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.8%, Avg loss: 1.976956 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 0.001839  [    0/50000]\n",
            "loss: 0.001988  [ 6400/50000]\n",
            "loss: 0.002623  [12800/50000]\n",
            "loss: 0.002392  [19200/50000]\n",
            "loss: 0.001899  [25600/50000]\n",
            "loss: 0.002447  [32000/50000]\n",
            "loss: 0.001747  [38400/50000]\n",
            "loss: 0.002641  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.0%, Avg loss: 1.979589 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 0.002583  [    0/50000]\n",
            "loss: 0.002538  [ 6400/50000]\n",
            "loss: 0.002279  [12800/50000]\n",
            "loss: 0.002464  [19200/50000]\n",
            "loss: 0.002084  [25600/50000]\n",
            "loss: 0.002424  [32000/50000]\n",
            "loss: 0.001559  [38400/50000]\n",
            "loss: 0.002563  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.8%, Avg loss: 1.978045 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 0.002743  [    0/50000]\n",
            "loss: 0.001464  [ 6400/50000]\n",
            "loss: 0.001395  [12800/50000]\n",
            "loss: 0.002411  [19200/50000]\n",
            "loss: 0.002735  [25600/50000]\n",
            "loss: 0.001939  [32000/50000]\n",
            "loss: 0.001897  [38400/50000]\n",
            "loss: 0.002809  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.9%, Avg loss: 1.984344 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 0.001585  [    0/50000]\n",
            "loss: 0.001846  [ 6400/50000]\n",
            "loss: 0.001619  [12800/50000]\n",
            "loss: 0.002408  [19200/50000]\n",
            "loss: 0.001845  [25600/50000]\n",
            "loss: 0.002647  [32000/50000]\n",
            "loss: 0.001917  [38400/50000]\n",
            "loss: 0.001849  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.2%, Avg loss: 1.985400 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 0.001589  [    0/50000]\n",
            "loss: 0.001925  [ 6400/50000]\n",
            "loss: 0.001631  [12800/50000]\n",
            "loss: 0.001719  [19200/50000]\n",
            "loss: 0.001590  [25600/50000]\n",
            "loss: 0.001328  [32000/50000]\n",
            "loss: 0.001807  [38400/50000]\n",
            "loss: 0.003986  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.8%, Avg loss: 1.990507 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 0.002010  [    0/50000]\n",
            "loss: 0.001778  [ 6400/50000]\n",
            "loss: 0.001550  [12800/50000]\n",
            "loss: 0.001813  [19200/50000]\n",
            "loss: 0.001824  [25600/50000]\n",
            "loss: 0.004908  [32000/50000]\n",
            "loss: 0.002040  [38400/50000]\n",
            "loss: 0.001801  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 1.982123 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 0.002268  [    0/50000]\n",
            "loss: 0.002834  [ 6400/50000]\n",
            "loss: 0.057767  [12800/50000]\n",
            "loss: 0.002313  [19200/50000]\n",
            "loss: 0.001366  [25600/50000]\n",
            "loss: 0.001416  [32000/50000]\n",
            "loss: 0.001799  [38400/50000]\n",
            "loss: 0.001427  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.0%, Avg loss: 1.987955 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 0.002249  [    0/50000]\n",
            "loss: 0.002250  [ 6400/50000]\n",
            "loss: 0.001702  [12800/50000]\n",
            "loss: 0.001433  [19200/50000]\n",
            "loss: 0.001818  [25600/50000]\n",
            "loss: 0.002727  [32000/50000]\n",
            "loss: 0.001851  [38400/50000]\n",
            "loss: 0.002341  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 1.992765 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 0.001424  [    0/50000]\n",
            "loss: 0.001473  [ 6400/50000]\n",
            "loss: 0.001994  [12800/50000]\n",
            "loss: 0.001530  [19200/50000]\n",
            "loss: 0.002818  [25600/50000]\n",
            "loss: 0.001488  [32000/50000]\n",
            "loss: 0.003180  [38400/50000]\n",
            "loss: 0.002527  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 1.993299 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 0.002059  [    0/50000]\n",
            "loss: 0.001438  [ 6400/50000]\n",
            "loss: 0.001320  [12800/50000]\n",
            "loss: 0.001805  [19200/50000]\n",
            "loss: 0.001272  [25600/50000]\n",
            "loss: 0.001786  [32000/50000]\n",
            "loss: 0.001934  [38400/50000]\n",
            "loss: 0.001490  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.8%, Avg loss: 1.995983 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 0.001202  [    0/50000]\n",
            "loss: 0.001616  [ 6400/50000]\n",
            "loss: 0.001961  [12800/50000]\n",
            "loss: 0.001599  [19200/50000]\n",
            "loss: 0.001456  [25600/50000]\n",
            "loss: 0.043410  [32000/50000]\n",
            "loss: 0.002017  [38400/50000]\n",
            "loss: 0.001359  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.8%, Avg loss: 2.006018 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 0.001217  [    0/50000]\n",
            "loss: 0.001848  [ 6400/50000]\n",
            "loss: 0.003122  [12800/50000]\n",
            "loss: 0.001455  [19200/50000]\n",
            "loss: 0.001368  [25600/50000]\n",
            "loss: 0.001495  [32000/50000]\n",
            "loss: 0.002124  [38400/50000]\n",
            "loss: 0.001492  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.9%, Avg loss: 1.997300 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "loss: 0.001573  [    0/50000]\n",
            "loss: 0.021806  [ 6400/50000]\n",
            "loss: 0.001710  [12800/50000]\n",
            "loss: 0.003153  [19200/50000]\n",
            "loss: 0.002076  [25600/50000]\n",
            "loss: 0.001554  [32000/50000]\n",
            "loss: 0.002929  [38400/50000]\n",
            "loss: 0.001993  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.8%, Avg loss: 2.010665 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "loss: 0.001126  [    0/50000]\n",
            "loss: 0.001665  [ 6400/50000]\n",
            "loss: 0.001434  [12800/50000]\n",
            "loss: 0.001379  [19200/50000]\n",
            "loss: 0.001686  [25600/50000]\n",
            "loss: 0.001938  [32000/50000]\n",
            "loss: 0.001922  [38400/50000]\n",
            "loss: 0.001472  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.6%, Avg loss: 2.010536 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "loss: 0.001257  [    0/50000]\n",
            "loss: 0.001533  [ 6400/50000]\n",
            "loss: 0.001447  [12800/50000]\n",
            "loss: 0.001309  [19200/50000]\n",
            "loss: 0.002456  [25600/50000]\n",
            "loss: 0.001586  [32000/50000]\n",
            "loss: 0.002157  [38400/50000]\n",
            "loss: 0.001405  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 2.005838 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "loss: 0.001608  [    0/50000]\n",
            "loss: 0.001587  [ 6400/50000]\n",
            "loss: 0.001039  [12800/50000]\n",
            "loss: 0.001909  [19200/50000]\n",
            "loss: 0.001404  [25600/50000]\n",
            "loss: 0.001340  [32000/50000]\n",
            "loss: 0.001695  [38400/50000]\n",
            "loss: 0.001779  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.9%, Avg loss: 2.005014 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "loss: 0.001909  [    0/50000]\n",
            "loss: 0.001918  [ 6400/50000]\n",
            "loss: 0.001302  [12800/50000]\n",
            "loss: 0.001696  [19200/50000]\n",
            "loss: 0.001109  [25600/50000]\n",
            "loss: 0.001920  [32000/50000]\n",
            "loss: 0.002124  [38400/50000]\n",
            "loss: 0.001659  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.8%, Avg loss: 2.013673 \n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "loss: 0.002158  [    0/50000]\n",
            "loss: 0.001227  [ 6400/50000]\n",
            "loss: 0.001653  [12800/50000]\n",
            "loss: 0.002225  [19200/50000]\n",
            "loss: 0.001608  [25600/50000]\n",
            "loss: 0.001624  [32000/50000]\n",
            "loss: 0.001775  [38400/50000]\n",
            "loss: 0.001134  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.8%, Avg loss: 2.012443 \n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "loss: 0.001342  [    0/50000]\n",
            "loss: 0.002259  [ 6400/50000]\n",
            "loss: 0.001708  [12800/50000]\n",
            "loss: 0.001551  [19200/50000]\n",
            "loss: 0.001373  [25600/50000]\n",
            "loss: 0.001659  [32000/50000]\n",
            "loss: 0.002024  [38400/50000]\n",
            "loss: 0.001512  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.8%, Avg loss: 2.016726 \n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "loss: 0.001263  [    0/50000]\n",
            "loss: 0.001922  [ 6400/50000]\n",
            "loss: 0.001699  [12800/50000]\n",
            "loss: 0.001964  [19200/50000]\n",
            "loss: 0.001468  [25600/50000]\n",
            "loss: 0.001126  [32000/50000]\n",
            "loss: 0.002029  [38400/50000]\n",
            "loss: 0.001174  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 2.028064 \n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "loss: 0.001385  [    0/50000]\n",
            "loss: 0.001694  [ 6400/50000]\n",
            "loss: 0.001544  [12800/50000]\n",
            "loss: 0.001161  [19200/50000]\n",
            "loss: 0.001877  [25600/50000]\n",
            "loss: 0.001391  [32000/50000]\n",
            "loss: 0.002316  [38400/50000]\n",
            "loss: 0.001657  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.6%, Avg loss: 2.030232 \n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "loss: 0.000897  [    0/50000]\n",
            "loss: 0.001552  [ 6400/50000]\n",
            "loss: 0.002239  [12800/50000]\n",
            "loss: 0.001507  [19200/50000]\n",
            "loss: 0.001597  [25600/50000]\n",
            "loss: 0.001769  [32000/50000]\n",
            "loss: 0.001411  [38400/50000]\n",
            "loss: 0.001068  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 2.024617 \n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "loss: 0.001093  [    0/50000]\n",
            "loss: 0.001398  [ 6400/50000]\n",
            "loss: 0.001528  [12800/50000]\n",
            "loss: 0.003422  [19200/50000]\n",
            "loss: 0.001407  [25600/50000]\n",
            "loss: 0.001228  [32000/50000]\n",
            "loss: 0.001888  [38400/50000]\n",
            "loss: 0.001537  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.8%, Avg loss: 2.032260 \n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "loss: 0.001612  [    0/50000]\n",
            "loss: 0.001923  [ 6400/50000]\n",
            "loss: 0.000873  [12800/50000]\n",
            "loss: 0.001311  [19200/50000]\n",
            "loss: 0.001598  [25600/50000]\n",
            "loss: 0.001396  [32000/50000]\n",
            "loss: 0.001277  [38400/50000]\n",
            "loss: 0.002337  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.6%, Avg loss: 2.037932 \n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "loss: 0.001180  [    0/50000]\n",
            "loss: 0.001062  [ 6400/50000]\n",
            "loss: 0.002129  [12800/50000]\n",
            "loss: 0.001225  [19200/50000]\n",
            "loss: 0.001658  [25600/50000]\n",
            "loss: 0.035586  [32000/50000]\n",
            "loss: 0.001065  [38400/50000]\n",
            "loss: 0.002145  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.8%, Avg loss: 2.028777 \n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "loss: 0.001084  [    0/50000]\n",
            "loss: 0.000994  [ 6400/50000]\n",
            "loss: 0.001270  [12800/50000]\n",
            "loss: 0.001849  [19200/50000]\n",
            "loss: 0.001337  [25600/50000]\n",
            "loss: 0.001032  [32000/50000]\n",
            "loss: 0.001320  [38400/50000]\n",
            "loss: 0.001267  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.8%, Avg loss: 2.033459 \n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "loss: 0.001147  [    0/50000]\n",
            "loss: 0.001070  [ 6400/50000]\n",
            "loss: 0.001259  [12800/50000]\n",
            "loss: 0.000896  [19200/50000]\n",
            "loss: 0.001287  [25600/50000]\n",
            "loss: 0.000743  [32000/50000]\n",
            "loss: 0.001314  [38400/50000]\n",
            "loss: 0.001940  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 2.032450 \n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "loss: 0.001496  [    0/50000]\n",
            "loss: 0.001408  [ 6400/50000]\n",
            "loss: 0.001223  [12800/50000]\n",
            "loss: 0.001198  [19200/50000]\n",
            "loss: 0.000997  [25600/50000]\n",
            "loss: 0.000918  [32000/50000]\n",
            "loss: 0.001318  [38400/50000]\n",
            "loss: 0.001168  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 2.039881 \n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "loss: 0.001484  [    0/50000]\n",
            "loss: 0.057307  [ 6400/50000]\n",
            "loss: 0.002516  [12800/50000]\n",
            "loss: 0.003447  [19200/50000]\n",
            "loss: 0.001076  [25600/50000]\n",
            "loss: 0.002293  [32000/50000]\n",
            "loss: 0.001290  [38400/50000]\n",
            "loss: 0.001278  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 2.033099 \n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "loss: 0.001773  [    0/50000]\n",
            "loss: 0.001119  [ 6400/50000]\n",
            "loss: 0.001242  [12800/50000]\n",
            "loss: 0.001121  [19200/50000]\n",
            "loss: 0.001792  [25600/50000]\n",
            "loss: 0.001558  [32000/50000]\n",
            "loss: 0.001215  [38400/50000]\n",
            "loss: 0.000870  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.8%, Avg loss: 2.038789 \n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "loss: 0.001323  [    0/50000]\n",
            "loss: 0.001100  [ 6400/50000]\n",
            "loss: 0.001058  [12800/50000]\n",
            "loss: 0.001837  [19200/50000]\n",
            "loss: 0.001545  [25600/50000]\n",
            "loss: 0.001044  [32000/50000]\n",
            "loss: 0.001257  [38400/50000]\n",
            "loss: 0.000849  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 2.037609 \n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "loss: 0.001136  [    0/50000]\n",
            "loss: 0.001611  [ 6400/50000]\n",
            "loss: 0.001386  [12800/50000]\n",
            "loss: 0.001151  [19200/50000]\n",
            "loss: 0.001800  [25600/50000]\n",
            "loss: 0.000944  [32000/50000]\n",
            "loss: 0.001117  [38400/50000]\n",
            "loss: 0.001003  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 2.035875 \n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "loss: 0.001556  [    0/50000]\n",
            "loss: 0.001010  [ 6400/50000]\n",
            "loss: 0.001237  [12800/50000]\n",
            "loss: 0.001382  [19200/50000]\n",
            "loss: 0.001098  [25600/50000]\n",
            "loss: 0.001365  [32000/50000]\n",
            "loss: 0.001493  [38400/50000]\n",
            "loss: 0.000818  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.6%, Avg loss: 2.046886 \n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "loss: 0.001449  [    0/50000]\n",
            "loss: 0.001142  [ 6400/50000]\n",
            "loss: 0.001210  [12800/50000]\n",
            "loss: 0.001065  [19200/50000]\n",
            "loss: 0.002005  [25600/50000]\n",
            "loss: 0.001491  [32000/50000]\n",
            "loss: 0.033343  [38400/50000]\n",
            "loss: 0.001073  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.8%, Avg loss: 2.047237 \n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "loss: 0.002512  [    0/50000]\n",
            "loss: 0.001101  [ 6400/50000]\n",
            "loss: 0.000975  [12800/50000]\n",
            "loss: 0.001360  [19200/50000]\n",
            "loss: 0.001017  [25600/50000]\n",
            "loss: 0.000948  [32000/50000]\n",
            "loss: 0.001224  [38400/50000]\n",
            "loss: 0.000886  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.8%, Avg loss: 2.050131 \n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "loss: 0.001377  [    0/50000]\n",
            "loss: 0.000960  [ 6400/50000]\n",
            "loss: 0.001102  [12800/50000]\n",
            "loss: 0.001158  [19200/50000]\n",
            "loss: 0.001174  [25600/50000]\n",
            "loss: 0.001414  [32000/50000]\n",
            "loss: 0.000976  [38400/50000]\n",
            "loss: 0.001074  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.6%, Avg loss: 2.048491 \n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "loss: 0.001276  [    0/50000]\n",
            "loss: 0.002161  [ 6400/50000]\n",
            "loss: 0.001213  [12800/50000]\n",
            "loss: 0.001172  [19200/50000]\n",
            "loss: 0.001258  [25600/50000]\n",
            "loss: 0.001124  [32000/50000]\n",
            "loss: 0.001365  [38400/50000]\n",
            "loss: 0.001192  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 2.058008 \n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "loss: 0.001053  [    0/50000]\n",
            "loss: 0.001332  [ 6400/50000]\n",
            "loss: 0.000943  [12800/50000]\n",
            "loss: 0.001106  [19200/50000]\n",
            "loss: 0.001347  [25600/50000]\n",
            "loss: 0.000944  [32000/50000]\n",
            "loss: 0.001329  [38400/50000]\n",
            "loss: 0.001461  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.6%, Avg loss: 2.054566 \n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "loss: 0.001617  [    0/50000]\n",
            "loss: 0.001067  [ 6400/50000]\n",
            "loss: 0.001256  [12800/50000]\n",
            "loss: 0.001274  [19200/50000]\n",
            "loss: 0.001212  [25600/50000]\n",
            "loss: 0.001478  [32000/50000]\n",
            "loss: 0.001432  [38400/50000]\n",
            "loss: 0.001674  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 2.055416 \n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "loss: 0.000937  [    0/50000]\n",
            "loss: 0.001558  [ 6400/50000]\n",
            "loss: 0.000833  [12800/50000]\n",
            "loss: 0.001421  [19200/50000]\n",
            "loss: 0.001111  [25600/50000]\n",
            "loss: 0.001068  [32000/50000]\n",
            "loss: 0.000934  [38400/50000]\n",
            "loss: 0.000986  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.6%, Avg loss: 2.054149 \n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "loss: 0.001384  [    0/50000]\n",
            "loss: 0.000768  [ 6400/50000]\n",
            "loss: 0.001353  [12800/50000]\n",
            "loss: 0.001665  [19200/50000]\n",
            "loss: 0.001924  [25600/50000]\n",
            "loss: 0.001263  [32000/50000]\n",
            "loss: 0.000883  [38400/50000]\n",
            "loss: 0.001220  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.6%, Avg loss: 2.056091 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 0.001389  [    0/50000]\n",
            "loss: 0.000805  [ 6400/50000]\n",
            "loss: 0.000930  [12800/50000]\n",
            "loss: 0.000880  [19200/50000]\n",
            "loss: 0.001956  [25600/50000]\n",
            "loss: 0.001300  [32000/50000]\n",
            "loss: 0.001441  [38400/50000]\n",
            "loss: 0.000909  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 2.065147 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuur8m03SUJG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2ItVonvLzuE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}